## ğŸ‘‹ Hi there!

<!--
**shreyansh26/shreyansh26** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

Iâ€™m a **Principal ML Engineer** at **Level AI**, where I focus on building and scaling large language models (LLMs) specifically for conversational AI. With over four years of experience in applied AI and research, Iâ€™ve worked extensively on end-to-end solutions in NLP and ML systems.

Before Level AI, I worked as a **Data Scientist** at **Mastercard AI Garage**, where I developed AI models to enhance transaction security and intelligence. I graduated in 2020 with a degree in Computer Science from the **Indian Institute of Technology (BHU) Varanasi**.

My technical interests include Natural Language Processing, ML Systems Engineeringâ€”including CUDA and Triton for high-performance computing, Privacy-preserving ML, and Cryptography. 

Iâ€™m always working on side projects, many of which involve implementing and experimenting with ideas from research papers, efficient kernels and other low-level stuff in LLM training/inference regime. You can find these projects here.



![](https://komarev.com/ghpvc/?username=shreyansh26&color=blue)

### ğŸ“« How to reach me
- ğ• Twitter/X: [@shreyansh_26](https://twitter.com/shreyansh_26)
- ğŸ‘¥ LinkedIn: [Shreyansh Singh](https://www.linkedin.com/in/shreyansh26/)
- ğŸ’» Website: [https://shreyansh26.github.io](https://shreyansh26.github.io)

### ğŸ“• Latest Blog Posts
<!-- BLOG-POST-LIST:START -->
- [Understanding Multi-Head Latent Attention &lpar;MLA&rpar;](https://shreyansh26.github.io/post/2025-11-08_multihead-latent-attention/)
- [Deriving the Gradient for the Backward Pass of Layer Normalization](https://shreyansh26.github.io/post/2025-06-04_layernorm-gradients/)
- [Notes from GTCâ€™25: CUDA Techniques to Maximize Compute and Instruction Throughput](https://shreyansh26.github.io/post/2025-04-04_gtc25-maximize-compute-instruction-throughput/)
- [Notes from GTCâ€™25: CUDA Techniques to Maximize Memory Bandwidth and Hide Latency - Part 1](https://shreyansh26.github.io/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-1/)
- [Notes from GTCâ€™25: CUDA Techniques to Maximize Memory Bandwidth and Hide Latency - Part 2](https://shreyansh26.github.io/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-2/)
<!-- BLOG-POST-LIST:END -->
